import os
import re
import requests
import json
from flask import Flask, render_template, request, Response
import logging
from filelock import FileLock
from pathlib import Path
import base64

class PersianLogFormatter(logging.Formatter):
    LEVEL_MAP = {
        logging.DEBUG: "Ø¯ÛŒØ¨Ø§Ú¯",
        logging.INFO: "Ø§Ø·Ù„Ø§Ø¹",
        logging.WARNING: "Ù‡Ø´Ø¯Ø§Ø±",
        logging.ERROR: "Ø®Ø·Ø§",
        logging.CRITICAL: "Ø¨Ø­Ø±Ø§Ù†ÛŒ",
    }
    def format(self, record):
        record.levelname = self.LEVEL_MAP.get(record.levelno, record.levelname)
        return super().format(record)

def setup_logging():
    log_format = '[%(asctime)s] [%(levelname)s]: %(message)s'
    date_format = '%Y-%m-%d %H:%M:%S'
    formatter = PersianLogFormatter(log_format, datefmt=date_format)
    root_logger = logging.getLogger()
    if root_logger.hasHandlers():
        root_logger.handlers.clear()
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    root_logger.addHandler(console_handler)
    root_logger.setLevel(logging.INFO)

setup_logging()

try:
    ALL_GEMINI_API_KEYS_STR = os.getenv('ALL_GEMINI_API_KEYS')
    if not ALL_GEMINI_API_KEYS_STR:
        raise RuntimeError("Ù…ØªØºÛŒØ± ALL_GEMINI_API_KEYS ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
    MASTER_API_KEYS = [key.strip() for key in ALL_GEMINI_API_KEYS_STR.split(',') if key.strip()]
    if not MASTER_API_KEYS:
        raise RuntimeError("Ù‡ÛŒÚ† Ú©Ù„ÛŒØ¯ Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¯Ø± ALL_GEMINI_API_KEYS ÛŒØ§ÙØª Ù†Ø´Ø¯.")
    
    COUNTER_FILE_PATH = '/dev/shm/gunicorn_key_counter.txt'
    lock_path = COUNTER_FILE_PATH + ".lock"
    lock = FileLock(lock_path)
    with lock:
        if not os.path.exists(COUNTER_FILE_PATH):
            logging.info(f"âœ… Ø§ÙˆÙ„ÛŒÙ† Ú©Ø§Ø±Ú¯Ø± Ø´Ø±ÙˆØ¹ Ø¨Ù‡ Ú©Ø§Ø± Ú©Ø±Ø¯. Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª {len(MASTER_API_KEYS)} Ú©Ù„ÛŒØ¯ Gemini Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")
            with open(COUNTER_FILE_PATH, 'w') as f:
                f.write('0')
            logging.info("Ø´Ù…Ø§Ø±Ù†Ø¯Ù‡ Ú†Ø±Ø®Ø´ Ú©Ù„ÛŒØ¯Ù‡Ø§ Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø´Ø¯.")

    CACHE_DIR = Path('/dev/shm/file_cache')
    CACHE_DIR.mkdir(parents=True, exist_ok=True)
    logging.info(f"Ù¾ÙˆØ´Ù‡ Ú©Ø´ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¯Ø± Ù…Ø³ÛŒØ± '{CACHE_DIR}' Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø³Øª.")

    META_DIR = Path('/dev/shm/chat_meta')
    META_DIR.mkdir(parents=True, exist_ok=True)
    logging.info(f"Ù¾ÙˆØ´Ù‡ Ù…ØªØ§Ø¯ÛŒØªØ§ÛŒ Ú†Øªâ€ŒÙ‡Ø§ Ø¯Ø± Ù…Ø³ÛŒØ± '{META_DIR}' Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø³Øª.")
            
except Exception as e:
    logging.critical(f"Ø®Ø·Ø§ÛŒ Ø¨Ø­Ø±Ø§Ù†ÛŒ Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ API ÛŒØ§ ØªÙ†Ø¸ÛŒÙ… Ú©Ø´/Ù…ØªØ§: {e}")
    raise

app = Flask(__name__)
GOOGLE_API_BASE_URL = 'https://generativelanguage.googleapis.com/v1beta/models'

# ------------------------ Ù‚ÙˆØ§Ù†ÛŒÙ†/Ù…ÙˆØ§Ø¯ Ø«Ø§Ø¨Øª ------------------------
BASE_RULES_FA = """
**Ø¯Ø³ØªÙˆØ±Ø§Ù„Ø¹Ù…Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø¬Ø¨Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¢Ù„ÙØ§:**
1) Ù‡ÙˆÛŒØª: ØªÙˆ Â«Ú†Øªâ€ŒØ¨Ø§Øª Ø¢Ù„ÙØ§Â» Ù‡Ø³ØªÛŒ Ú©Ù‡ ØªÙˆØ³Ø· Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¢Ù„ÙØ§ ØªÙˆØ³Ø¹Ù‡ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡â€ŒØ§ÛŒ. ÙˆØ¸ÛŒÙÙ‡â€ŒØ§Øª Ú©Ù…Ú© Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø± Ø¯Ø± Ù‡Ù…Ù‡â€ŒÛŒ Ø²Ù…ÛŒÙ†Ù‡â€ŒÙ‡Ø§Ø³Øª.
2) Ù¾Ø±Ù‡ÛŒØ² Ø§Ø² Ø§Ù…ØªÙ†Ø§Ø¹ Ø¨ÛŒâ€ŒØ¬Ø§: Ø¨Ù‡ Ø¬Ø§ÛŒ Ø§Ù…ØªÙ†Ø§Ø¹ØŒ Ø±Ø§Ù‡â€ŒØ­Ù„ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†/Ø§ÛŒÙ…Ù† Ø¨Ø¯Ù‡.
3) ØªØ­Ù„ÛŒÙ„ Ø¬Ø§Ù…Ø¹ Ú†Ù†Ø¯Ø±Ø³Ø§Ù†Ù‡â€ŒØ§ÛŒ:
   - Ù‡Ø± Ù†ÙˆØ¹ ÙØ§ÛŒÙ„ (ØªØµÙˆÛŒØ±ØŒ ÙˆÛŒØ¯ÛŒÙˆØŒ ØµØ¯Ø§ØŒ PDFØŒ Ù…ØªÙ†ØŒ Ú©ÙØ¯ Ùˆ...) Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ùˆ Ù…Ø­ØªÙˆØ§ Ø±Ø§ Ø´Ø±Ø­ Ø¨Ø¯Ù‡.
   - Ù¾Ø§Ø³Ø® Ø±Ø§ Ø¨Ø§ ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ ÙØ§ÛŒÙ„ Ø´Ø±ÙˆØ¹ Ú©Ù† (Ù…Ø«Ù„Ø§Ù‹: Â«Ø§ÛŒÙ† ÛŒÚ© ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø§Ø³Øª Ú©Ù‡...Â»).
   - Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± ÙÙ‚Ø· ÙØ§ÛŒÙ„ ÙØ±Ø³ØªØ§Ø¯ Ùˆ ØµØ±Ø§Ø­ØªØ§Ù‹ Ø³Ø§Ø®Øª/ÙˆÛŒØ±Ø§ÛŒØ´ ØªØµÙˆÛŒØ± Ù†Ø®ÙˆØ§Ø³ØªØŒ ÙÙ‚Ø· ØªØ­Ù„ÛŒÙ„ Ú©Ù† (Ø§Ø¨Ø²Ø§Ø± ØªØµÙˆÛŒØ± Ø±Ø§ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù†Ú©Ù†).
4) ØªØµÙˆÛŒØ± (Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ Ø§Ù„Ø²Ø§Ù…ÛŒ Ø¯Ø± Ø³Ø§Ø®Øª/ÙˆÛŒØ±Ø§ÛŒØ´):
   - Ø§ÙˆÙ„ÙˆÛŒØª Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§: handle_specific_edit > change_image_aspect_ratio > regenerate_with_enhancement > generate_image > perform_internet_search
   - Ø®Ø±ÙˆØ¬ÛŒ Ø§Ø¨Ø²Ø§Ø± Ø¨Ø§ÛŒØ¯ functionCall ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø§Ø´Ø¯Ø› Ø´Ø¨Ù‡â€ŒÚ©Ø¯ Ù…Ø«Ù„ print(handle_specific_edit(...)) ÛŒØ§ Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ functionCall: ... Ù…Ù…Ù†ÙˆØ¹.
5) ÙˆÛŒØ±Ø§ÛŒØ´â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ§Ù¾ÛŒ: Ø§Ú¯Ø± Ø¯Ø³ØªÙˆØ± ØªÚ©Ù…ÛŒÙ„ÛŒ Ø¢Ù…Ø¯ØŒ Ø¨Ø§ Ø¯Ø³ØªÙˆØ± Ù‚Ø¨Ù„ÛŒ Ø§Ø¯ØºØ§Ù… Ú©Ù† Ùˆ Ø¨Ø¹Ø¯ ÙˆÛŒØ±Ø§ÛŒØ´ Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ø¨Ø¯Ù‡.
6) Ú¯ÙØªÚ¯Ùˆ: Ø§Ú¯Ø± Ù¾ÛŒØ§Ù… Ù…Ø­Ø§ÙˆØ±Ù‡â€ŒØ§ÛŒ/ØªØ´Ú©Ø± Ø¨ÙˆØ¯ØŒ Ø§Ø¨Ø²Ø§Ø± ØªØµÙˆÛŒØ± Ø±Ø§ Ù†Ø®ÙˆØ§Ù†Ø› Ù¾Ø§Ø³Ø® Ú©ÙˆØªØ§Ù‡ Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ø¯Ù‡.
7) Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ ØºÛŒØ±ØªØµÙˆÛŒØ±ÛŒ (Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒØŒ Ù†Ú¯Ø§Ø±Ø´ØŒ Ø¢Ù…ÙˆØ²Ø´ Ùˆ...): Ù¾Ø§Ø³Ø® Ù…ÙÛŒØ¯ Ø¨Ø¯Ù‡Ø› Ø¨Ø±Ø§ÛŒ Ú©Ø¯ØŒ Ø¨Ù„Ø§Ú© Markdown (```lang) Ø¨Ø¯Ù‡.
"""

# ------------------------ Ø§Ø¨Ø²Ø§Ø±/Ú©Ø´ ÙØ§ÛŒÙ„ ------------------------
def get_file_data_from_url(url):
    try:
        logging.info(f"Ø´Ø±ÙˆØ¹ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ ÙØ§ÛŒÙ„ Ø§Ø² URL: {url}")
        response = requests.get(url, timeout=60)
        response.raise_for_status()
        content_type = response.headers.get('Content-Type', 'application/octet-stream')
        file_content_bytes = response.content
        base64_encoded_data = base64.b64encode(file_content_bytes).decode('utf-8')
        logging.info(f"ÙØ§ÛŒÙ„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯. Ù†ÙˆØ¹: {content_type}, Ø­Ø¬Ù…: {len(file_content_bytes)} Ø¨Ø§ÛŒØª")
        return {"mimeType": content_type, "data": base64_encoded_data}
    except requests.exceptions.RequestException as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ ÙØ§ÛŒÙ„ Ø§Ø² URL {url}: {e}")
        return None

def get_and_increment_key_index():
    lock_path = COUNTER_FILE_PATH + ".lock"
    lock = FileLock(lock_path)
    with lock:
        try:
            with open(COUNTER_FILE_PATH, 'r') as f:
                current_index = int(f.read().strip())
        except (FileNotFoundError, ValueError):
            current_index = 0
        index_to_use = current_index % len(MASTER_API_KEYS)
        next_index = (current_index + 1)
        with open(COUNTER_FILE_PATH, 'w') as f:
            f.write(str(next_index))
        return index_to_use

def get_keys_for_request():
    start_index = get_and_increment_key_index()
    return MASTER_API_KEYS[start_index:] + MASTER_API_KEYS[:start_index]

# ------------------------ Ù…ØªØ§ÛŒ Ú†Øª ------------------------
def _meta_path(chat_id: str) -> Path:
    safe_id = ''.join(c for c in str(chat_id) if c.isalnum() or c in ('-', '_'))
    return META_DIR / f"{safe_id}.json"

def load_chat_meta(chat_id: str) -> dict:
    path = _meta_path(chat_id)
    lock = FileLock(str(path) + ".lock")
    with lock:
        if path.exists():
            try:
                return json.load(open(path, 'r', encoding='utf-8'))
            except Exception as e:
                logging.warning(f"Ø®ÙˆØ§Ù†Ø¯Ù† Ù…ØªØ§ÛŒ Ú†Øª {chat_id} Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯: {e}")
                return {}
        return {}

def save_chat_meta(chat_id: str, meta: dict):
    path = _meta_path(chat_id)
    lock = FileLock(str(path) + ".lock")
    with lock:
        try:
            with open(path, 'w', encoding='utf-8') as f:
                json.dump(meta or {}, f, ensure_ascii=False)
        except Exception as e:
            logging.warning(f"Ø°Ø®ÛŒØ±Ù‡ Ù…ØªØ§ÛŒ Ú†Øª {chat_id} Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯: {e}")

def update_chat_meta(chat_id: str, **kwargs):
    meta = load_chat_meta(chat_id)
    meta.update({k: v for k, v in kwargs.items() if v is not None})
    save_chat_meta(chat_id, meta)

# ------------------------ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ ------------------------
def get_all_tools():
    search_tool = {
        "name": "perform_internet_search",
        "description": "ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ù‡â€ŒØ±ÙˆØ²ØŒ ÙˆÙ‚Ø§ÛŒØ¹ Ø¬Ø§Ø±ÛŒØŒ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ Ùˆ... Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´ÙˆØ¯.",
        "parameters": {"type": "OBJECT","properties": {"query": {"type": "STRING"}},"required": ["query"]}
    }
    image_tools = [
        {
            "name": "generate_image",
            "description": "Ø³Ø§Ø®Øª ØªØµÙˆÛŒØ± Ø¬Ø¯ÛŒØ¯ (Ù†Ù‡ ØªÙˆØµÛŒÙ Ù…ØªÙ†ÛŒ).",
            "parameters": {"type": "OBJECT","properties": {
                "english_prompt": {"type": "STRING"},
                "aspect_ratio": {"type": "STRING"},
                "initial_response_text": {"type": "STRING"},
                "follow_up_text": {"type": "STRING"}
            },"required": ["english_prompt", "initial_response_text", "follow_up_text"]}
        },
        {
            "name": "handle_specific_edit",
            "description": "ØªØºÛŒÛŒØ± Ù…Ø´Ø®Øµ Ø±ÙˆÛŒ ØªØµÙˆÛŒØ± Ù‚Ø¨Ù„ÛŒØ› Ø¯Ø³ØªÙˆØ± Ø¬Ø¯ÛŒØ¯ Ø±Ø§ Ø¯Ø± ØµÙˆØ±Øª Ù„Ø²ÙˆÙ… Ø¨Ø§ Ù‚Ø¨Ù„ÛŒ Ø§Ø¯ØºØ§Ù… Ú©Ù†.",
            "parameters": {"type": "OBJECT","properties": {"edit_request": {"type": "STRING"}},"required": ["edit_request"]}
        },
        {
            "name": "regenerate_with_enhancement",
            "description": "Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒ/Ù…Ø¨Ù‡Ù…Ø› Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø±ÙØ¹ Ø§Ø¨Ù‡Ø§Ù….",
            "parameters": {"type": "OBJECT","properties": {
                "enhancement_request": {"type": "STRING"},
                "previous_english_prompt": {"type": "STRING"},
                "previous_aspect_ratio": {"type": "STRING"}
            },"required": ["enhancement_request", "previous_english_prompt", "previous_aspect_ratio"]}
        },
        {
            "name": "change_image_aspect_ratio",
            "description": "ØªØºÛŒÛŒØ± Ù†Ø³Ø¨Øª/Ø§Ù†Ø¯Ø§Ø²Ù‡ ØªØµÙˆÛŒØ± Ù‚Ø¨Ù„ÛŒ.",
            "parameters": {"type": "OBJECT","properties": {
                "new_aspect_ratio": {"type": "STRING"},
                "previous_english_prompt": {"type": "STRING"}
            },"required": ["new_aspect_ratio", "previous_english_prompt"]}
        }
    ]
    return [{"function_declarations": image_tools + [search_tool]}]

# ------------------------ Ù¾Ø±Ø§Ù…Ù¾Øªâ€ŒØ³Ø§Ø²ÛŒ/Ø§Ø¯ØºØ§Ù… ------------------------
def enhance_prompt(base_prompt, enhancement_request, model):
    api_key = get_keys_for_request()[0] 
    url = f"{GOOGLE_API_BASE_URL}/{model}:generateContent?key={api_key}"
    system_prompt = f"""You are an expert prompt engineer. Merge the base English image prompt with the user's modification (Persian or English). Return only the final, ready-to-use English prompt.

Base Prompt: "{base_prompt}"
User's Request: "{enhancement_request}"
"""
    payload = {"contents": [{"role": "user", "parts": [{"text": system_prompt}]}],"generationConfig": { "temperature": 0.7 }}
    try:
        response = requests.post(url, json=payload, timeout=45)
        response.raise_for_status()
        enhanced_prompt = response.json()["candidates"][0]["content"]["parts"][0]["text"].strip()
        logging.info(f"âœ… Ù¾Ø±Ø§Ù…Ù¾Øª Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØª: {enhanced_prompt}")
        return enhanced_prompt
    except Exception as e:
        logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± enhance_prompt: {e}")
        return f"{base_prompt}, {enhancement_request}"

def create_artistic_prompt(user_prompt, model):
    api_key = get_keys_for_request()[0]
    url = f"{GOOGLE_API_BASE_URL}/{model}:generateContent?key={api_key}"
    system_instruction = "Convert user's (possibly Persian) idea to a highly-detailed English prompt. Output ONLY the final English prompt."
    payload = {
        "contents": [{"role": "user", "parts": [{"text": user_prompt}]}],
        "systemInstruction": {"parts": [{"text": system_instruction}]},
        "generationConfig": { "temperature": 0.7 }
    }
    try:
        r = requests.post(url, json=payload, timeout=45)
        r.raise_for_status()
        return r.json()["candidates"][0]["content"]["parts"][0]["text"].strip()
    except Exception as e:
        logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± create_artistic_prompt: {e}")
        return user_prompt

def merge_edit_prompt(chat_id: str, user_edit_request: str, model: str) -> str:
    meta = load_chat_meta(chat_id)
    base_prompt = (meta.get("last_edit_prompt") or meta.get("last_english_prompt") or "").strip()
    if base_prompt:
        try:
            return enhance_prompt(base_prompt, user_edit_request, model) or user_edit_request
        except Exception as e:
            logging.warning(f"Ø§Ø¯ØºØ§Ù… Ù¾Ø±Ø§Ù…Ù¾Øª ÙˆÛŒØ±Ø§ÛŒØ´ Ù†Ø§Ù…ÙˆÙÙ‚: {e}")
            return user_edit_request
    return user_edit_request

# ------------------------ Ø¬Ø³ØªØ¬Ùˆ ------------------------
def stream_search_results(query):
    logging.info(f"ğŸš€ Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ: '{query}'")
    keys_to_try = get_keys_for_request()
    search_model = 'gemini-2.5-flash' 
    url = f"{GOOGLE_API_BASE_URL}/{search_model}:streamGenerateContent?alt=sse"
    payload = {"contents": [{"role": "user", "parts": [{"text": query}]}],"tools": [{"google_search": {}}],"systemInstruction": {"parts": [{"text": "Answer in Persian."}]}}
    for api_key in keys_to_try:
        try:
            with requests.post(url, params={'key': api_key}, json=payload, stream=True, timeout=120) as response:
                if response.status_code == 429:
                    logging.warning("Ú©Ù„ÛŒØ¯ Ø¬Ø³ØªØ¬Ùˆ Ù…Ø³Ø¯ÙˆØ¯. Ú©Ù„ÛŒØ¯ Ø¨Ø¹Ø¯ÛŒ...")
                    continue
                response.raise_for_status()
                for line in response.iter_lines():
                    if line:
                        yield f"{line.decode('utf-8')}\n\n"
                return
        except requests.exceptions.RequestException as e:
            logging.warning(f"Ø®Ø·Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ: {e}. Ú©Ù„ÛŒØ¯ Ø¨Ø¹Ø¯ÛŒ...")
            continue
    yield f"data: {json.dumps({'error': {'code': 'SEARCH_FAILED','message': 'Ø³Ø±ÙˆÛŒØ³ Ø¬Ø³ØªØ¬Ùˆ Ù…ÙˆÙ‚ØªØ§Ù‹ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.'}})}\n\n"

# ------------------------ Fallback parser Ø¨Ø±Ø§ÛŒ Ø´Ø¨Ù‡â€ŒÚ©Ø¯ Ùˆ Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ functionCall: ... ------------------------
def parse_tool_call_from_text(text: str):
    if not text:
        return None
    # Ø­Ø§Ù„Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù:
    if "functionCall" in text:
        m = re.search(r'functionCall\s*:\s*(\w+)\s*KATEX_INLINE_OPEN', text, flags=re.I)
        if m:
            name = m.group(1)
            return (name, {})  # Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ø¨Ø¹Ø¯Ø§Ù‹ Ù¾Ø± Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    if "handle_specific_edit" in text:
        m = re.search(r'edit_request\s*=\s*(["\'])(?P<val>.+?)\1', text, flags=re.S)
        if m: return ("handle_specific_edit", {"edit_request": m.group("val")})
        m2 = re.search(r'handle_specific_edit\s*KATEX_INLINE_OPEN', text)
        if m2: return ("handle_specific_edit", {})
    if "change_image_aspect_ratio" in text:
        m_ar = re.search(r'new_aspect_ratio\s*=\s*(["\'])(?P<ar>.+?)\1', text, flags=re.S)
        args = {}
        if m_ar: args["new_aspect_ratio"] = m_ar.group("ar")
        return ("change_image_aspect_ratio", args) if "change_image_aspect_ratio" in text else None
    if "regenerate_with_enhancement" in text:
        return ("regenerate_with_enhancement", {})
    if "generate_image" in text and "english_prompt" in text:
        m_ep = re.search(r'english_prompt\s*=\s*(["\'])(?P<ep>.+?)\1', text, flags=re.S)
        m_ar = re.search(r'aspect_ratio\s*=\s*(["\'])(?P<ar>.+?)\1', text, flags=re.S)
        args = {}
        if m_ep: args["english_prompt"] = m_ep.group("ep")
        if m_ar: args["aspect_ratio"]  = m_ar.group("ar")
        return ("generate_image", args)
    if "print" in text and "handle_specific_edit" in text:
        return ("handle_specific_edit", {})
    return None

def is_tool_like_text(txt: str) -> bool:
    if not txt: return False
    patterns = [
        r'\bfunctionCall\s*:',
        r'\bhandle_specific_edit\s*KATEX_INLINE_OPEN',
        r'\bchange_image_aspect_ratio\s*KATEX_INLINE_OPEN',
        r'\bregenerate_with_enhancement\s*KATEX_INLINE_OPEN',
        r'\bgenerate_image\s*KATEX_INLINE_OPEN',
        r'print\s*KATEX_INLINE_OPEN\s*handle_specific_edit',
    ]
    return any(re.search(p, txt, flags=re.I) for p in patterns)

def sse_text_event(text: str) -> str:
    return f"data: {json.dumps({'candidates':[{'content':{'parts':[{'text': text}]}}]})}\n\n"

# ------------------------ Intent Classifier ------------------------
def classify_user_intent(user_text: str) -> dict:
    """
    intents: NONE, SPECIFIC_EDIT, ASPECT_RATIO_CHANGE, QUALITY_ENHANCEMENT, NEW_IMAGE, CODE_TASK
    optional: normalized_edit, new_aspect_ratio, code_language
    """
    if not user_text or not user_text.strip():
        return {"intent":"NONE"}
    keys_to_try = get_keys_for_request()
    classify_model = 'gemini-2.5-flash'
    url = f"{GOOGLE_API_BASE_URL}/{classify_model}:generateContent"
    system = (
        "You classify ONLY the latest message.\n"
        "Return strict JSON: {\"intent\":\"...\", \"normalized_edit\":\"...\", \"new_aspect_ratio\":\"...\", \"code_language\":\"...\"}\n"
        "intents=[NONE,SPECIFIC_EDIT,ASPECT_RATIO_CHANGE,QUALITY_ENHANCEMENT,NEW_IMAGE,CODE_TASK]. "
        "Thanks/ack/greetings => NONE. Code/markup requests => CODE_TASK."
    )
    payload = {
        "contents": [{"role":"user","parts":[{"text": user_text}]}],
        "systemInstruction": {"parts":[{"text": system}]},
        "generationConfig": {"temperature": 0.0, "maxOutputTokens": 128}
    }
    for api_key in keys_to_try:
        try:
            r = requests.post(f"{url}?key={api_key}", json=payload, timeout=20)
            if r.status_code == 429: continue
            r.raise_for_status()
            txt = r.json()["candidates"][0]["content"]["parts"][0]["text"].strip().strip('`').strip()
            s, e = txt.find('{'), txt.rfind('}')
            if s != -1 and e != -1: txt = txt[s:e+1]
            data = json.loads(txt)
            if "intent" not in data: return {"intent":"NONE"}
            return data
        except Exception as e:
            logging.warning(f"Intent classify failed: {e}")
            continue
    return {"intent":"NONE"}

# ------------------------ Ø§Ø³ØªØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ/Ú©Ø¯/ØªØ­Ù„ÛŒÙ„ ÙØ§ÛŒÙ„ ------------------------
def stream_text_only(user_text: str, model_name: str):
    keys_to_try = get_keys_for_request()
    system_text = BASE_RULES_FA + """
[TURN MODE: TEXT ONLY]
- Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ Ø±Ø§ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù†Ú©Ù†.
- ÛŒÚ© Ù¾Ø§Ø³Ø® Ú©ÙˆØªØ§Ù‡ØŒ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ùˆ ÙØ§Ø±Ø³ÛŒ Ø¨Ø¯Ù‡.
- Ù‡Ø±Ú¯Ø² Ù†Ø§Ù… Ø§Ø¨Ø²Ø§Ø± ÛŒØ§ ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ functionCall Ø±Ø§ Ø¯Ø± Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù†ÙˆÛŒØ³.
- Ø§Ø² Ø¹Ø°Ø±Ø®ÙˆØ§Ù‡ÛŒ/Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÚ¯ÙˆÛŒÛŒ Ø§Ø¬ØªÙ†Ø§Ø¨ Ú©Ù†.
"""
    contents = [{"role":"user","parts":[{"text": user_text }]}]
    responded_text = ""
    for api_key in keys_to_try:
        try:
            url = f"{GOOGLE_API_BASE_URL}/{model_name}:streamGenerateContent?alt=sse&key={api_key}"
            payload = {
                "contents": contents,
                "tools": None,
                "systemInstruction": {"parts": [{"text": system_text}]},
                "generationConfig": {"temperature": 0.3, "maxOutputTokens": 128}
            }
            with requests.post(url, json=payload, stream=True, timeout=60) as resp:
                if resp.status_code == 429:
                    logging.warning("Ú©Ù„ÛŒØ¯ API Ù…Ø³Ø¯ÙˆØ¯. Ú©Ù„ÛŒØ¯ Ø¨Ø¹Ø¯ÛŒ...")
                    continue
                resp.raise_for_status()
                for line in resp.iter_lines():
                    if not line: continue
                    if line.startswith(b"data: "):
                        chunk_str = line.decode("utf-8")[6:]
                        try:
                            data_chunk = json.loads(chunk_str)
                            part = data_chunk.get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0]
                            if "text" in part:
                                t = part["text"]
                                if is_tool_like_text(t):
                                    # Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ø¨Ú¯ÛŒØ±
                                    continue
                                responded_text += t
                                yield sse_text_event(t)
                        except Exception:
                            continue
                # Ø§Ú¯Ø± Ù‡ÛŒÚ† Ù…ØªÙ†ÛŒ Ù†Ø¯Ø§Ø¯ØŒ ÛŒÚ© Ù¾Ø§Ø³Ø® Ú©ÙˆØªØ§Ù‡ Ø¨Ø¯Ù‡
                if not responded_text:
                    default_reply = "Ù…Ø±Ø³ÛŒ Ø§Ø² Ø¨Ø§Ø²Ø®ÙˆØ±Ø¯Øª! Ø®ÙˆØ´Ø­Ø§Ù„Ù… Ú©Ù‡ Ø±Ø§Ø¶ÛŒ Ø¨ÙˆØ¯ÛŒ ğŸŒŸ"
                    yield sse_text_event(default_reply)
                return
        except requests.exceptions.RequestException as e:
            logging.warning(f"Text-only error: {e}")
            continue
    yield f"data: {json.dumps({'error': {'code':'TEXT_STREAM_FAILED','message':'Ù¾Ø§Ø³Ø® Ù…ØªÙ†ÛŒ Ù…ÙˆÙ‚ØªØ§Ù‹ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.'}})}\n\n"

def stream_code_reply(user_text: str, model_name: str, code_language: str = None):
    keys_to_try = get_keys_for_request()
    lang = (code_language or "").lower()
    if lang not in {"html","css","javascript","python","sql","bash","json","yaml","xml","markdown","typescript","csharp","java","c","cpp","php","go","rust","kotlin","swift"}:
        lang = "html"
    system_text = BASE_RULES_FA + f"""
[TURN MODE: CODE]
- Ù‡ÛŒÚ† Ø§Ø¨Ø²Ø§Ø±ÛŒ Ø±Ø§ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù†Ú©Ù†.
- Ú©Ø¯ Ú©Ø§Ù…Ù„ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø¬Ø±Ø§ ØªÙˆÙ„ÛŒØ¯ Ú©Ù† Ø¯Ø§Ø®Ù„ ```{lang}.
- ØªÙˆØ¶ÛŒØ­ Ú©ÙˆØªØ§Ù‡ ÙØ§Ø±Ø³ÛŒ Ù…Ø¬Ø§Ø²ØŒ ØªÙ…Ø±Ú©Ø² Ø±ÙˆÛŒ Ú©Ø¯.
"""
    contents = [{"role":"user","parts":[{"text": user_text }]}]
    for api_key in keys_to_try:
        try:
            url = f"{GOOGLE_API_BASE_URL}/{model_name}:streamGenerateContent?alt=sse&key={api_key}"
            payload = {
                "contents": contents,
                "tools": None,
                "systemInstruction": {"parts": [{"text": system_text}]},
                "generationConfig": {"temperature": 0.2, "maxOutputTokens": 2048}
            }
            with requests.post(url, json=payload, stream=True, timeout=120) as response:
                if response.status_code == 429:
                    logging.warning("Ú©Ù„ÛŒØ¯ API Ù…Ø³Ø¯ÙˆØ¯. Ú©Ù„ÛŒØ¯ Ø¨Ø¹Ø¯ÛŒ...")
                    continue
                response.raise_for_status()
                for line in response.iter_lines():
                    if line:
                        # Ø¯Ø± Ù¾Ø§Ø³Ø® Ú©Ø¯ØŒ Ø¨Ù‡â€ŒØ·ÙˆØ± Ù…Ø¹Ù…ÙˆÙ„ ÙÙ‚Ø· Ù…ØªÙ† Ù…ÛŒâ€ŒØ¢ÛŒØ¯
                        yield line.decode('utf-8') + "\n\n"
                return
        except requests.exceptions.RequestException as e:
            logging.warning(f"Code stream error: {e}")
            continue
    yield f"data: {json.dumps({'error': {'code':'CODE_STREAM_FAILED','message':'ØªÙˆÙ„ÛŒØ¯ Ú©Ø¯ Ù…ÙˆÙ‚ØªØ§Ù‹ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.'}})}\n\n"

def stream_file_analysis(history_for_gemini, model_name: str):
    keys_to_try = get_keys_for_request()
    system_text = BASE_RULES_FA + """
[TURN MODE: FILE ANALYSIS]
- Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ Ø±Ø§ ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù†Ú©Ù†.
- ÙØ§ÛŒÙ„ Ø¶Ù…ÛŒÙ…Ù‡â€ŒØ´Ø¯Ù‡ Ø¯Ø± Ø¢Ø®Ø±ÛŒÙ† Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ ØªØ­Ù„ÛŒÙ„ Ú©Ù†: Ù†ÙˆØ¹ ÙØ§ÛŒÙ„ Ø±Ø§ Ø¯Ù‚ÛŒÙ‚ ØªØ´Ø®ÛŒØµ Ø¨Ø¯Ù‡ Ùˆ Ù…Ø­ØªÙˆØ§ÛŒ Ø¢Ù† Ø±Ø§ Ø®Ù„Ø§ØµÙ‡ Ùˆ Ù…Ù†Ø¸Ù… Ø´Ø±Ø­ Ø¨Ø¯Ù‡.
- Ø§Ú¯Ø± ØªØµÙˆÛŒØ± Ø§Ø³Øª Ùˆ Ú©Ø§Ø±Ø¨Ø± ØµØ±ÙØ§Ù‹ ØªØ­Ù„ÛŒÙ„ Ø®ÙˆØ§Ø³ØªÙ‡ØŒ ÙÙ‚Ø· Ù…Ø­ØªÙˆØ§ÛŒ ØªØµÙˆÛŒØ± Ø±Ø§ ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡ (Ù†Ù‡ Ø³Ø§Ø®Øª/ÙˆÛŒØ±Ø§ÛŒØ´).
"""
    # Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒÙ… pass-through Ú©Ù†ÛŒÙ…Ø› Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ ÙÙ‚Ø· Ù…ØªÙ† Ù…ÛŒâ€ŒØ¢ÛŒØ¯
    for api_key in keys_to_try:
        try:
            url = f"{GOOGLE_API_BASE_URL}/{model_name}:streamGenerateContent?alt=sse&key={api_key}"
            payload = {
                "contents": history_for_gemini,
                "tools": None,
                "systemInstruction": {"parts": [{"text": system_text}]},
                "generationConfig": {"temperature": 0.3, "maxOutputTokens": 1024}
            }
            with requests.post(url, json=payload, stream=True, timeout=180) as response:
                if response.status_code == 429:
                    logging.warning("Ú©Ù„ÛŒØ¯ API Ù…Ø³Ø¯ÙˆØ¯. Ú©Ù„ÛŒØ¯ Ø¨Ø¹Ø¯ÛŒ...")
                    continue
                response.raise_for_status()
                for line in response.iter_lines():
                    if line:
                        yield line.decode('utf-8') + "\n\n"
                return
        except requests.exceptions.RequestException as e:
            logging.warning(f"File analysis error: {e}")
            continue
    yield f"data: {json.dumps({'error': {'code':'FILE_ANALYSIS_FAILED','message':'ØªØ­Ù„ÛŒÙ„ ÙØ§ÛŒÙ„ Ù…ÙˆÙ‚ØªØ§Ù‹ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.'}})}\n\n"

# ------------------------ Ø±ÙˆØªâ€ŒÙ‡Ø§ ------------------------
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/healthz')
def healthz():
    return Response(json.dumps({"status": "ok"}), status=200, mimetype='application/json')

@app.route('/chat', methods=['POST'])
def chat():
    data = request.json
    if not data:
        return Response(json.dumps({"error": "Invalid request"}), status=400, mimetype='application/json')
    
    model = data.get('model', 'gemini-2.5-flash')
    history = data.get('history', [])
    action_payload = data.get('action')
    chat_id = data.get('chatId')

    if not chat_id:
        return Response(json.dumps({"error": "chatId is required"}), status=400, mimetype='application/json')

    # -------- Ú©Ø´ ÙØ§ÛŒÙ„: ÛŒØ§ÙØªÙ† Ø¢Ø®Ø±ÛŒÙ† Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø± Ùˆ ØªØ²Ø±ÛŒÙ‚ Ù‚Ø·Ø¹ÛŒ inlineData --------
    def find_last_user_index(hist):
        for i in range(len(hist)-1, -1, -1):
            if hist[i].get('role') == 'user':
                return i
        return None

    cache_file_path = CACHE_DIR / f"{chat_id}.json"
    cache_lock = FileLock(str(cache_file_path) + ".lock")
    file_data_for_gemini = None

    with cache_lock:
        last_user_idx = find_last_user_index(history)
        last_user_message = history[last_user_idx] if last_user_idx is not None else None

        # 1) Ø§Ú¯Ø± inlineData Ø¯Ø± Ø¨Ø¯Ù†Ù‡ Ù‡Ø³Øª
        if last_user_message:
            existing_inline = next((p for p in (last_user_message.get('parts') or []) if 'inlineData' in p), None)
            if existing_inline:
                file_data_for_gemini = existing_inline['inlineData']
                with open(cache_file_path, 'w') as f:
                    json.dump(file_data_for_gemini, f)
                logging.info(f"inlineData Ø¬Ø¯ÛŒØ¯ Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ú©Ø´ Ø´Ø¯.")

        # 2) Ø§Ø² Ú©Ø´
        if not file_data_for_gemini and cache_file_path.exists():
            try:
                with open(cache_file_path, 'r') as f:
                    file_data_for_gemini = json.load(f)
                logging.info(f"inlineData Ø§Ø² Ú©Ø´ Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯.")
            except (json.JSONDecodeError, FileNotFoundError):
                logging.warning("Ú©Ø´ Ø®Ø±Ø§Ø¨/Ø­Ø°Ù Ø´Ø¯Ù‡ Ø¨ÙˆØ¯.")

        # 3) Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø§Ø² URL
        if not file_data_for_gemini:
            logging.info("Ú©Ø´ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª. ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø² ØªØ§Ø±ÛŒØ®Ú†Ù‡.")
            file_url_to_recover = None
            for message in reversed(history):
                # ÙÙ‚Ø· ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø¯Ø± Ù†Ø¸Ø± Ø¨Ú¯ÛŒØ±
                if message.get('role') == 'user':
                    file_part = next((p for p in (message.get('parts') or []) if p.get('fileUrl')), None)
                    if file_part:
                        file_url_to_recover = file_part['fileUrl']
                        break
            if file_url_to_recover:
                recovered = get_file_data_from_url(file_url_to_recover)
                if recovered:
                    file_data_for_gemini = recovered
                    with open(cache_file_path, 'w') as f:
                        json.dump(file_data_for_gemini, f)
                    logging.info("ÙØ§ÛŒÙ„ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ùˆ Ú©Ø´ Ø´Ø¯.")
            else:
                logging.info("URL Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")

        # 4) ØªØ²Ø±ÛŒÙ‚ inlineData Ø¨Ù‡ Ø¢Ø®Ø±ÛŒÙ† Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø±
        if file_data_for_gemini and last_user_message:
            parts = last_user_message.get('parts', []) or []
            already = any('inlineData' in p for p in parts)
            if not already:
                parts.insert(0, {'inlineData': file_data_for_gemini})
                last_user_message['parts'] = parts
                logging.info("inlineData Ø¨Ù‡ Ø¢Ø®Ø±ÛŒÙ† Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø± ØªØ²Ø±ÛŒÙ‚ Ø´Ø¯.")

    # -------- Ø§Ú©Ø´Ù† Ù…Ø³ØªÙ‚ÛŒÙ… clarify --------
    if action_payload and action_payload.get('intent') == 'regenerate_with_enhancement':
        def stream_action_result():
            try:
                base_prompt = action_payload.get("base_english_prompt")
                enhancement_request = action_payload.get("enhancement_request")
                aspect_ratio = action_payload.get("aspect_ratio", "9:16")
                if not base_prompt or not enhancement_request:
                    yield f"data: {json.dumps({'error': {'code':'MISSING_ARGS','message':'Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù„Ø§Ø²Ù… Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.'}})}\n\n"
                    return
                logging.info(f"ğŸš€ Ø¨Ù‡Ø¨ÙˆØ¯ Ù¾Ø±Ø§Ù…Ù¾Øª Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ø³Ø§Ø²ÛŒ: '{enhancement_request}'")
                new_prompt = enhance_prompt(base_prompt, enhancement_request, model)
                yield f"data: {json.dumps({'intent':'generate_image','english_prompt': new_prompt,'aspect_ratio': aspect_ratio})}\n\n"
            except Exception as e:
                logging.error(f"âŒ Ø®Ø·Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø§Ú©Ø´Ù†: {e}")
                yield f"data: {json.dumps({'error': {'code':'ACTION_EXECUTION_FAILED','message': str(e)}})}\n\n"
        return Response(stream_action_result(), mimetype='text/event-stream')

    # ------------------------ Ø§Ø³ØªØ±ÛŒÙ… Ø§ØµÙ„ÛŒ ------------------------
    def stream_events():
        def send_event(event_data):
            return f"data: {json.dumps(event_data)}\n\n"

        # ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¨Ø±Ø§ÛŒ Gemini (ÙÙ‚Ø· text/inlineData/ØªÙˆØ§Ø¨Ø¹)
        history_for_gemini = []
        for msg in history:
            if 'role' not in msg: continue
            new_msg = {'role': msg['role'], 'parts': []}
            for part in (msg.get('parts') or []):
                if isinstance(part, dict) and any(k in part for k in ['text','inlineData','functionCall','functionResponse']):
                    new_msg['parts'].append(part)
            if new_msg['parts']:
                history_for_gemini.append(new_msg)

        # ØªØ´Ø®ÛŒØµ Ø²Ù…ÛŒÙ†Ù‡
        def find_last_user_index_local(hist):
            for i in range(len(hist)-1, -1, -1):
                if hist[i].get('role') == 'user':
                    return i
            return None

        last_user_idx = find_last_user_index_local(history)
        last_user_text = ""
        has_inline_file = False
        if last_user_idx is not None:
            lu = history[last_user_idx]
            last_user_text = ''.join(p.get('text','') for p in (lu.get('parts') or [])).strip()
            has_inline_file = any('inlineData' in p for p in (lu.get('parts') or []))

        image_in_recent_history = False
        for m in history[-4:]:
            if m.get('role') == 'model' and any('image_url' in p or 'edited_images' in p for p in (m.get('parts') or [])):
                image_in_recent_history = True
                break

        intent_info = classify_user_intent(last_user_text) if last_user_text else {"intent":"NONE"}
        intent = (intent_info.get("intent") or "NONE").upper()
        logging.info(f"Intent: {intent} | inline={has_inline_file} | image_recent={image_in_recent_history}")

        # 1) Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ
        if intent == "CODE_TASK":
            yield from stream_code_reply(last_user_text, model, intent_info.get("code_language"))
            return

        # 2) Ø¨Ø¹Ø¯ Ø§Ø² ØªØµÙˆÛŒØ±: ØªØ´Ú©Ø±/Ú¯ÙØªâ€ŒÙˆÚ¯Ùˆ => Ù…ØªÙ† Ú©ÙˆØªØ§Ù‡
        # FIX: Ø§ÙˆÙ„ÙˆÛŒØª Ù¾Ø§Ø³Ø® Ù…ØªÙ†ÛŒ Ú©ÙˆØªØ§Ù‡ Ø¨Ø¹Ø¯ Ø§Ø² ØªÙˆÙ„ÛŒØ¯/ÙˆÛŒØ±Ø§ÛŒØ´ ØªØµÙˆÛŒØ± Ø­ØªÛŒ Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯ inlineData
        if image_in_recent_history and last_user_text and intent == "NONE":
            yield from stream_text_only(last_user_text, model)
            return

        # 3) Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ù‡Ø³Øª Ùˆ Ú©Ø§Ø±Ø¨Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª ØªØµÙˆÛŒØ±/Ú©Ø¯ Ù†Ø¯Ø§Ø¯Ù‡ => ØªØ­Ù„ÛŒÙ„ ÙØ§ÛŒÙ„
        if has_inline_file and intent in {"NONE"}:
            yield from stream_file_analysis(history_for_gemini, model)
            return

        # 4) Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ØªØµÙˆÛŒØ± Ø¨Ø± Ø§Ø³Ø§Ø³ intent
        if image_in_recent_history and last_user_text:
            if intent == "SPECIFIC_EDIT":
                merged = merge_edit_prompt(chat_id, intent_info.get("normalized_edit") or last_user_text, model)
                update_chat_meta(chat_id, last_edit_prompt=merged)
                yield send_event({"intent": "edit_image", "prompt": merged})
                return
            elif intent == "ASPECT_RATIO_CHANGE":
                meta = load_chat_meta(chat_id)
                ep = meta.get("last_edit_prompt") or meta.get("last_english_prompt") or ""
                new_ar = intent_info.get("new_aspect_ratio") or meta.get("last_aspect_ratio") or "9:16"
                yield send_event({"intent": "generate_image", "english_prompt": ep, "aspect_ratio": new_ar})
                return
            elif intent == "QUALITY_ENHANCEMENT":
                meta = load_chat_meta(chat_id)
                prev_ep = meta.get("last_edit_prompt") or meta.get("last_english_prompt") or ""
                prev_ar = meta.get("last_aspect_ratio") or "9:16"
                enh = intent_info.get("normalized_edit") or last_user_text
                yield send_event({
                    "intent": "clarify_action",
                    "question": "Ø¨Ø³ÛŒØ§Ø± Ø®Ø¨! ØªØµÙˆÛŒØ± ÙØ¹Ù„ÛŒ Ø±Ø§ ÙˆÛŒØ±Ø§ÛŒØ´ Ú©Ù†Ù… ÛŒØ§ ÛŒÚ© ØªØµÙˆÛŒØ± Ø¬Ø¯ÛŒØ¯ Ø¨Ø³Ø§Ø²Ù…ØŸ",
                    "options": {
                        "edit": {"label": "ÙˆÛŒØ±Ø§ÛŒØ´ Ù‡Ù…ÛŒÙ† ØªØµÙˆÛŒØ±", "intent": "edit_image", "prompt": enh},
                        "regenerate": {"label": "Ø³Ø§Ø®Øª ØªØµÙˆÛŒØ± Ø¬Ø¯ÛŒØ¯", "intent": "regenerate_with_enhancement", "base_english_prompt": prev_ep, "enhancement_request": enh, "aspect_ratio": prev_ar}
                    }
                })
                return
            elif intent == "NEW_IMAGE":
                ep = create_artistic_prompt(last_user_text, model)
                update_chat_meta(chat_id, last_english_prompt=ep, last_aspect_ratio="9:16", last_edit_prompt=None)
                yield send_event({
                    "intent": "generate_image_with_text",
                    "text": "Ø¯Ø± Ø­Ø§Ù„ Ø³Ø§Ø®Øª ØªØµÙˆÛŒØ± Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø´Ù…Ø§...",
                    "image_generation_payload": {"english_prompt": ep, "aspect_ratio": "9:16"},
                    "follow_up_text": "ØªØµÙˆÛŒØ± Ø´Ù…Ø§ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯!"
                })
                return

        # 5) Ù…Ø³ÛŒØ± Ø¬Ù†Ø±Ø§Ù„ Ø¨Ø§ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ ØªØµÙˆÛŒØ±
        tools_for_request = get_all_tools()
        final_system_prompt = BASE_RULES_FA + """
[TURN MODE: GENERAL]
- Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ ØªØµÙˆÛŒØ± Ø§Ø² Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†Ø› Ø¯Ø± ØºÛŒØ± Ø§ÛŒÙ† ØµÙˆØ±Øª Ù¾Ø§Ø³Ø® Ù…ØªÙ†ÛŒ/Ú©ÙØ¯ Ø¨Ø¯Ù‡.
- Ø§Ø² Ø´Ø¨Ù‡â€ŒÚ©Ø¯ Ø¨Ø±Ø§ÛŒ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ Ø®ÙˆØ¯Ø¯Ø§Ø±ÛŒ Ú©Ù† (ÙÙ‚Ø· functionCall ÙˆØ§Ù‚Ø¹ÛŒ). Ù‡Ø±Ú¯Ø² Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ 'functionCall: ...' Ø¯Ø± Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù†ÙˆÛŒØ³.
"""

        keys_to_try = get_keys_for_request()
        accumulated_function_call_args = None
        function_call_name = None

        for api_key in keys_to_try:
            try:
                url = f"{GOOGLE_API_BASE_URL}/{model}:streamGenerateContent?alt=sse&key={api_key}"
                payload = {"contents": history_for_gemini, "tools": tools_for_request, "systemInstruction": {"parts": [{"text": final_system_prompt}]}}
                with requests.post(url, json=payload, stream=True, timeout=720) as response:
                    if response.status_code == 429:
                        logging.warning("Ú©Ù„ÛŒØ¯ API Ù…Ø³Ø¯ÙˆØ¯. Ú©Ù„ÛŒØ¯ Ø¨Ø¹Ø¯ÛŒ...")
                        continue
                    response.raise_for_status()

                    for line in response.iter_lines():
                        if not line: continue
                        if line.startswith(b'data: '):
                            chunk_str = line.decode('utf-8')[6:]
                            try:
                                data_chunk = json.loads(chunk_str)
                                part = data_chunk.get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0]

                                if "functionCall" in part:
                                    if not accumulated_function_call_args:
                                        accumulated_function_call_args = {}
                                        function_call_name = part["functionCall"].get("name")
                                    args_chunk = part["functionCall"].get("args", {})
                                    for k, v in (args_chunk or {}).items():
                                        if k not in accumulated_function_call_args:
                                            accumulated_function_call_args[k] = v
                                        elif isinstance(accumulated_function_call_args[k], str):
                                            accumulated_function_call_args[k] += str(v)
                                elif "text" in part:
                                    t = part["text"]
                                    # ÙÛŒÙ„ØªØ± Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ø´Ø¨ÛŒÙ‡ functionCall:
                                    if is_tool_like_text(t):
                                        continue
                                    # Ù¾Ø§Ø³â€ŒØªØ±Ùˆ Ù…ØªÙ† Ù¾Ø§Ú©â€ŒØ´Ø¯Ù‡
                                    yield sse_text_event(t)

                            except Exception:
                                continue

                if accumulated_function_call_args:
                    args = accumulated_function_call_args
                    logging.info(f"âœ… functionCall: {function_call_name} args={args}")

                    if function_call_name == "handle_specific_edit":
                        raw_req = (args.get("edit_request") or "").strip()
                        if not raw_req:
                            yield send_event({"error": {"code":"EMPTY_EDIT_REQUEST","message":"Ø¯Ø³ØªÙˆØ± ÙˆÛŒØ±Ø§ÛŒØ´ Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯."}})
                            return
                        merged = merge_edit_prompt(chat_id, raw_req, model)
                        update_chat_meta(chat_id, last_edit_prompt=merged)
                        yield send_event({"intent":"edit_image","prompt": merged})
                        return

                    elif function_call_name == "regenerate_with_enhancement":
                        meta = load_chat_meta(chat_id)
                        prev_ep = args.get("previous_english_prompt") or meta.get("last_edit_prompt") or meta.get("last_english_prompt") or ""
                        prev_ar = args.get("previous_aspect_ratio") or meta.get("last_aspect_ratio") or "9:16"
                        enhancement_request = args.get("enhancement_request", "")
                        yield send_event({
                            "intent":"clarify_action",
                            "question":"Ø¨Ø³ÛŒØ§Ø± Ø®Ø¨! Ø¨Ø§ Ø§ÛŒÙ† ØªØºÛŒÛŒØ±Ø§Øª Ú†Ù‡ Ú©Ù†Ù…ØŸ",
                            "options":{
                                "edit":{"label":"ÙˆÛŒØ±Ø§ÛŒØ´ Ù‡Ù…ÛŒÙ† ØªØµÙˆÛŒØ±","intent":"edit_image","prompt": enhancement_request},
                                "regenerate":{"label":"Ø³Ø§Ø®Øª ØªØµÙˆÛŒØ± Ø¬Ø¯ÛŒØ¯","intent":"regenerate_with_enhancement","base_english_prompt": prev_ep,"enhancement_request": enhancement_request,"aspect_ratio": prev_ar}
                            }
                        })
                        return

                    elif function_call_name == "change_image_aspect_ratio":
                        meta = load_chat_meta(chat_id)
                        ep = args.get("previous_english_prompt") or meta.get("last_edit_prompt") or meta.get("last_english_prompt") or ""
                        new_ar = args.get("new_aspect_ratio") or meta.get("last_aspect_ratio") or "9:16"
                        yield send_event({"intent":"generate_image","english_prompt": ep,"aspect_ratio": new_ar})
                        return

                    elif function_call_name == "generate_image":
                        ep = args.get("english_prompt")
                        ar = args.get("aspect_ratio", "9:16")
                        update_chat_meta(chat_id, last_english_prompt=ep, last_aspect_ratio=ar, last_edit_prompt=None)
                        yield send_event({
                            "intent":"generate_image_with_text",
                            "text": args.get("initial_response_text"),
                            "image_generation_payload": {"english_prompt": ep,"aspect_ratio": ar},
                            "follow_up_text": args.get("follow_up_text")
                        })
                        return

                    elif function_call_name == "perform_internet_search":
                        yield from stream_search_results(args.get('query'))
                        return

                # Fallback: Ø´Ø¨Ù‡â€ŒÚ©Ø¯/Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ø§Ø¨Ø²Ø§Ø±
                return

            except requests.exceptions.RequestException as e:
                if getattr(e, "response", None) is not None:
                    logging.error(f"HTTP Ø®Ø·Ø§ Ø§Ø² Gemini: {e.response.status_code} - {e.response.text}. Ú©Ù„ÛŒØ¯ Ø¨Ø¹Ø¯ÛŒ...")
                else:
                    logging.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Gemini: {e}. Ú©Ù„ÛŒØ¯ Ø¨Ø¹Ø¯ÛŒ...")
                continue

        yield send_event({"error": {"code": "ALL_KEYS_FAILED", "message": "ØªÙ…Ø§Ù… Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ API Ø®Ø·Ø§ Ø¯Ø§Ø¯Ù†Ø¯ ÛŒØ§ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨ÙˆØ¯."}})

    return Response(stream_events(), mimetype='text/event-stream')

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=7860)
